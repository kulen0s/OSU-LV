"""Zadatak 5.5.1 Skripta zadatak_1.py generira umjetni binarni klasifikacijski problem s dvije
 ulazne veliˇ cine. Podaci su podijeljeni na skup za uˇ cenje i skup za testiranje modela.
 a) Prikažite podatke za uˇ cenje u x1−x2 ravnini matplotlib biblioteke pri ˇ cemu podatke obojite
 s obzirom na klasu. Prikažite i podatke iz skupa za testiranje, ali za njih koristite drugi
 marker (npr. ’x’). Koristite funkciju scatter koja osim podataka prima i parametre c i
 cmap kojima je mogu´ ce definirati boju svake klase.
 b) Izgradite model logistiˇ cke regresije pomo´ cu scikit-learn biblioteke na temelju skupa poda
taka za uˇ cenje.
 c) Prona¯ dite u atributima izgra¯ denog modela parametre modela. Prikažite granicu odluke
 nauˇcenog modela u ravnini x1 −x2 zajedno s podacima za uˇcenje. Napomena: granica
 odluke u ravnini x1−x2 definirana je kao krivulja: θ0+θ1x1+θ2x2 = 0.
 d) Provedite klasifikaciju skupa podataka za testiranje pomo´ cu izgra¯ denog modela logistiˇ cke
 regresije. Izraˇ cunajte i prikažite matricu zabune na testnim podacima. Izraˇ cunate toˇ cnost,
 preciznost i odziv na skupu podataka za testiranje.
 e) Prikažite skup za testiranje u ravnini x1 −x2. Zelenom bojom oznaˇ cite dobro klasificirane
 primjere dok pogrešno klasificirane primjere oznaˇ cite crnom bojom.
 """
import numpy as np
import matplotlib
import matplotlib.pyplot as plt

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression 


X, y = make_classification(n_samples=200, n_features=2, n_redundant=0, n_informative=2,
                            random_state=213, n_clusters_per_class=1, class_sep=1)

# train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)

#a)
plt.figure(figsize=(8,6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', label='Train data')
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', marker='x', label='Test data')

plt.xlabel("X1")
plt.ylabel("X2")
plt.title("Umjetni binarni klasifikacijski problem")
plt.legend()
plt.grid(True)
plt.show()

#b)
LogRegression_model = LogisticRegression ()
LogRegression_model.fit( X_train , y_train )

#c)
# Pronalaženje parametara modela
theta0 = LogRegression_model.intercept_[0]
theta1, theta2 = LogRegression_model.coef_[0]

# Prikaz granice odluke
x1_values = np.linspace(np.min(X_train[:, 0]), np.max(X_train[:, 0]), 100)
x2_values = (-1/theta2) * (theta0 + theta1 * x1_values)

# Prikaz podataka za učenje
plt.figure(figsize=(8, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', label='Train data')

# Prikaz granice odluke
plt.plot(x1_values, x2_values, color='black', linestyle='--', label='Decision boundary')

plt.xlabel("X1")
plt.ylabel("X2")
plt.title("Decision boundary and training data")
plt.legend()
plt.grid(True)
plt.show()


#c)
coef = LogRegression_model.coef_
intercept = LogRegression_model.intercept_

# Definiranje x1 vrijednosti za granicu odluke
x1_values = np.array([X_train[:, 0].min(), X_train[:, 0].max()])

# Računanje x2 vrijednosti za granicu odluke
x2_values = -(intercept + coef[0, 0] * x1_values) / coef[0, 1]

# Prikaz granice odluke i podataka za učenje
plt.figure(figsize=(8, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Paired, edgecolors='k', label='Podaci za učenje')
plt.plot(x1_values, x2_values, c='red', label='Granica odluke')
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Granica odluke naučenog modela logističke regresije')
plt.legend()
plt.grid(True)
plt.show()

#d)
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay, recall_score
from sklearn.metrics import classification_report

y_pred = LogRegression_model.predict(X_test)

conf_matrix = confusion_matrix(y_test,y_pred)
print("\tMatrica zabune:",conf_matrix)
disp = ConfusionMatrixDisplay ( confusion_matrix (y_test , y_pred ))
disp . plot ()
plt . show ()

accuracy = accuracy_score(y_test,y_pred)
print("\nTočnost:",accuracy)

recall = recall_score(y_test, y_pred)
print("\nOdziv:",recall)

print(classification_report(y_test , y_pred))

#e)
y_pred = LogRegression_model.predict(X_test)

correct_indices = np.where(y_pred == y_test)[0]
incorrect_indices = np.where(y_pred != y_test)[0]

plt.figure(figsize=(8, 6))
plt.scatter(X_test[correct_indices, 0], X_test[correct_indices, 1], c='green', label='Dobro klasificirani')
plt.scatter(X_test[incorrect_indices, 0], X_test[incorrect_indices, 1], c='black', label='Pogrešno klasificirani')
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Skup za testiranje s označenim dobro i pogrešno klasificiranim primjerima')
plt.legend()
plt.grid(True)
plt.show()



Zadatak 5.5.2 Skripta zadatak_2.py uˇcitava podatkovni skup Palmer Penguins [1]. Ovaj
podatkovni skup sadrži mjerenja provedena na tri razliˇcite vrste pingvina (’Adelie’, ’Chinstrap’,
’Gentoo’) na tri razliˇcita otoka u podruˇcju Palmer Station, Antarktika. Vrsta pingvina
odabrana je kao izlazna veliˇcina i pri tome su klase oznaˇcene s cjelobrojnim vrijednostima
0, 1 i 2. Ulazne veliˇcine su duljina kljuna (’bill_length_mm’) i duljina peraje u mm (’flipper_
length_mm’). Za vizualizaciju podatkovnih primjera i granice odluke u skripti je dostupna
funkcija plot_decision_region.
a) Pomo´cu stupˇcastog dijagrama prikažite koliko primjera postoji za svaku klasu (vrstu
pingvina) u skupu podataka za uˇcenje i skupu podataka za testiranje. Koristite numpy
funkciju unique.
b) Izgradite model logistiˇcke regresije pomo´cu scikit-learn biblioteke na temelju skupa podataka
za uˇcenje.
c) Pronad¯ite u atributima izgrad¯enog modela parametre modela. Koja je razlika u odnosu na
binarni klasifikacijski problem iz prvog zadatka?
d) Pozovite funkciju plot_decision_region pri ˇcemu joj predajte podatke za uˇcenje i
izgrad¯eni model logisticˇke regresije. Kako komentirate dobivene rezultate?
e) Provedite klasifikaciju skupa podataka za testiranje pomoc´u izgrad¯enog modela logisticˇke
regresije. Izraˇcunajte i prikažite matricu zabune na testnim podacima. Izraˇcunajte toˇcnost.
Pomo´cu classification_report funkcije izraˇcunajte vrijednost ˇcetiri glavne metrike

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression




labels= {0:'Adelie', 1:'Chinstrap', 2:'Gentoo'}

def plot_decision_regions(X, y, classifier, resolution=0.02):
    plt.figure()
    # setup marker generator and color map
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])
    
    # plot the decision surface
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
    np.arange(x2_min, x2_max, resolution))
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)
    plt.xlim(xx1.min(), xx1.max())
    plt.ylim(xx2.min(), xx2.max())
    
    # plot class examples
    for idx, cl in enumerate(np.unique(y)):
        plt.scatter(x=X[y == cl, 0],
                    y=X[y == cl, 1],
                    alpha=0.8,
                    c=colors[idx],
                    marker=markers[idx],
                    edgecolor = 'w',
                    label=labels[cl])

# ucitaj podatke
df = pd.read_csv("penguins.csv")

# izostale vrijednosti po stupcima
print(df.isnull().sum())

# spol ima 11 izostalih vrijednosti; izbacit cemo ovaj stupac
df = df.drop(columns=['sex'])

# obrisi redove s izostalim vrijednostima
df.dropna(axis=0, inplace=True)

# kategoricka varijabla vrsta - kodiranje
df['species'].replace({'Adelie' : 0,
                        'Chinstrap' : 1,
                        'Gentoo': 2}, inplace = True)

print(df.info())

# izlazna velicina: species
output_variable = ['species']

# ulazne velicine: bill length, flipper_length
input_variables = ['bill_length_mm',
                    'flipper_length_mm']

X = df[input_variables].to_numpy()
y = df[output_variable].to_numpy()

# podjela train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

#a)

unique_train, counts_train = np.unique(y_train, return_counts=True)
class_counts_train = dict(zip(unique_train, counts_train))

unique_test, counts_test = np.unique(y_test, return_counts=True)
class_counts_test = dict(zip(unique_test, counts_test))

plt.figure(figsize=(10, 6))
plt.bar(class_counts_train.keys(), class_counts_train.values(), color='blue', alpha=0.5, label='Train')
plt.bar(class_counts_test.keys(), class_counts_test.values(), color='red', alpha=0.5, label='Test')
plt.xlabel('Klasa')
plt.ylabel('Broj primjera')
plt.title('Broj primjera po klasi u skupu za učenje i testiranje')
plt.xticks(list(labels.keys()), labels.values())
plt.legend()
plt.grid(True)
plt.show()

#b)
model = LogisticRegression()
model.fit(X_train, y_train)

#c)
coefficients = model.coef_
print("Koeficijenti modela:")
print(coefficients)

intercepts = model.intercept_
print("Parametri odsječka na y-osi:")
print(intercepts)

for i, label in labels.items():
    coefficients_class = coefficients[i]
    print(f"Koeficijenti za klasu {label}: {coefficients_class}")

for i, label in labels.items():
    intercept_class = intercepts[i]
    print(f"Koeficijenti za klasu {label}: {intercept_class}")


#d)
#plot_decision_regions(X_train, y_train.ravel(), model)
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Granice odluke modela logističke regresije na skupu za učenje')
plt.legend()
plt.show()

#e)
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

y_pred = model.predict(X_test)

conf_matrix = confusion_matrix(y_test, y_pred)
print("Matrica zabune:")
print(conf_matrix)

accuracy = accuracy_score(y_test, y_pred)
print("Točnost: {:.2f}".format(accuracy))

report = classification_report(y_test, y_pred, target_names=list(labels.values()))
print("Classification Report:")
print(report)


#f)
"""Classification Report (za input_variables2):
              precision    recall  f1-score   support

      Adelie       1.00      0.93      0.96        27
   Chinstrap       0.89      1.00      0.94        17
      Gentoo       1.00      1.00      1.00        25

    accuracy                           0.97        69
   macro avg       0.96      0.98      0.97        69
weighted avg       0.97      0.97      0.97        69

Classification Report (za input_variables):
              precision    recall  f1-score   support

      Adelie       0.96      0.89      0.92        27
   Chinstrap       0.94      0.88      0.91        17
      Gentoo       0.89      1.00      0.94        25

    accuracy                           0.93        69
   macro avg       0.93      0.92      0.93        69
weighted avg       0.93      0.93      0.93        69

Klasifikacija je malo bolja s 4 ulazne veličine nego s 2, no nije značajna razlika."""


